% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/speech.R
\name{gl_speech_recognise}
\alias{gl_speech_recognise}
\alias{gl_speech_recognize}
\title{Call Google Speech API}
\usage{
gl_speech_recognise(audio_source, encoding = c("LINEAR16", "FLAC", "MULAW",
  "AMR", "AMR_WB", "OGG_OPUS", "SPEEX_WITH_HEADER_BYTE"),
  sampleRateHertz = 16000L, languageCode = "en-US", maxAlternatives = 1L,
  profanityFilter = FALSE, speechContexts = NULL)

gl_speech_recognize(audio_source, encoding = c("LINEAR16", "FLAC", "MULAW",
  "AMR", "AMR_WB", "OGG_OPUS", "SPEEX_WITH_HEADER_BYTE"),
  sampleRateHertz = 16000L, languageCode = "en-US", maxAlternatives = 1L,
  profanityFilter = FALSE, speechContexts = NULL)
}
\arguments{
\item{audio_source}{File location of audio data, or Google Cloud Storage URI}

\item{encoding}{Encoding of audio data sent}

\item{sampleRateHertz}{Sample rate in Hertz of audio data. Valid values \code{8000-48000}. Optimal \code{16000}}

\item{languageCode}{Language of the supplied audio as a \code{BCP-47} language tag}

\item{maxAlternatives}{Maximum number of recognition hypotheses to be returned. \code{0-30}}

\item{profanityFilter}{If \code{TRUE} will attempt to filter out profanities}

\item{speechContexts}{An optional character vector of context to assist the speech recognition}
}
\value{
A tibble of two columns: \code{transcript} and the \code{confidence} with the number of rows equal to the \code{maxAlternatives}
}
\description{
Turn audio into text
}
\details{
Google Cloud Speech API enables developers to convert audio to text by applying powerful
neural network models in an easy to use API.
The API recognizes over 80 languages and variants, to support your global user base.
You can transcribe the text of users dictating to an applicationâ€™s microphone,
enable command-and-control through voice, or transcribe audio files, among many other use cases.
Recognize audio uploaded in the request, and integrate with your audio storage on Google Cloud Storage,
by using the same technology Google uses to power its own products.
}
\section{AudioEncoding}{


Audio encoding of the data sent in the audio message. All encodings support only 1 channel (mono) audio.
Only FLAC and WAV include a header that describes the bytes of audio that follow the header.
The other encodings are raw audio bytes with no header.
For best results, the audio source should be captured and transmitted using a
lossless encoding (FLAC or LINEAR16).
Recognition accuracy may be reduced if lossy codecs, which include the other codecs listed in this section,
are used to capture or transmit the audio, particularly if background noise is present.

Read more on audio encodings here \url{https://cloud.google.com/speech/docs/encoding}
}

\examples{

\dontrun{

test_audio <- system.file("woman1_wb.wav", package = "googleLanguageR")
result <- gl_speech_recognise(test_audio)

result2 <- gl_speech_recognise(test_audio, maxAlternatives = 2L)

result_brit <- gl_speech_recognise(test_audio, languageCode = "en-GB")

}


}
\seealso{
\url{https://cloud.google.com/speech/reference/rest/v1/speech/recognize}
}
